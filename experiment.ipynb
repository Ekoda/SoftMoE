{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, torch, random\n",
    "from torchvision import datasets, transforms\n",
    "from src import Config, ImageTokenizer, TokenizedImagesDataset, prepare_data, VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 12000)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = datasets.MNIST('data', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "config = Config()\n",
    "tokenizer = ImageTokenizer(config)\n",
    "\n",
    "train_data, val_data = prepare_data(mnist_data, tokenizer, config, val_split=0.2)\n",
    "\n",
    "len(train_data.dataset), len(val_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiitzwbo66/4z0fSpI3kiubpFlWPqY85buP4Qea7vWfiBpfg3X7+x8G+EtN065tLmW3a+nLXEjbW25Td9wHB4yetT/FDU11/4beDtd1W3ij8QXhl3ui7S8KkjJA9fkI9MnFeQ1teF/EEnhjWDqkEQkuUgljgJOPLd0Kh/qMk1QsLK51fVbeygV5bm6mWNAOSzMcf1rsvivq0Fz4itdBsJ3l07w/app0JP8ToMO35gDP+zXBUVveDb2bTvE8F7bELPBDPJGxGcMIXINYRJJJJJJ6k0lf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA60lEQVR4AWNgGIGAO/zK379/99vCvM4IZYhJMjDE2hv9B3IZb5p/hklD6El//wDB9UUpkWf//pmBKsfwDCh5y0IUKOr19892VMnQX58dxPggYhiSnC+fw1X//1sFZTNB6ExhkFPAwOvf930wNoQ+/+c4TGDS33MwJpQ+/8cLJvIMXdLhx2SYHNDdaXA2mOH21xsmYPwZ4TSIg0TX74VJFnNugzGhtBEvTMD4w58QGBuDdvtzCUMMLrDujwKcjc6w/HuAG10Mzl/4QRXOZmCABh9UhF3y+G0kSRYkNgPDv+8rkPmoOn/fPoMsCQArTU/CSL/HJgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = random.randint(0, len(mnist_data) - 1)\n",
    "image, _ = mnist_data[index]\n",
    "\n",
    "transforms.functional.to_pil_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VisionTransformer(config)\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through the whole dataset and check the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
